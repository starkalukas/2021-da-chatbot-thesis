\section{Systemarchitektur}\label{sec:systemarchitektur}

Es gibt 3 groÃŸe Services, das Chat Widget ~\ref{sec:chat-widget} auf der Schulhomepage, das Dashboard ~\ref{sec:dashboard} und das Backend ~\ref{sec:backend}.
Das System, das im Zuge der Arbeit entstand, sieht dabei folgendermaÃŸen aus:

\begin{figure}[hbt!]
    \centering
    \includegraphics[scale=0.2]{pics/systemarchitektur}
    \caption{Systemarchitektur}
    \label{fig:impl:architektur}
\end{figure}

Es gibt zwei virtuelle Ubuntu Maschinen, nÃ¤mlich eine fÃ¼r den Chat und eine fÃ¼r Rasa und das Backend.
Dadurch, dass der Chat auf die Seite der HTL Leonding Seite kommt, wird dadurch nur noch eine VM benÃ¶tigt.

Der Chat wird dabei gerade mit NGINX gehostet.
Dieser Server kommuniziert mit Rasa direkt Ã¼ber REST, wenn die Benutzerin oder der Benutzer eine Nachricht sendet, wird diese an Rasa gesendet und Rasa antwortet mit der passenden Antwort.
Das Dashboard ~\ref{sec:dashboard} wird auf GH Pages gehostet, dieses kommuniziert mit dem Backend Ã¼ber REST.
Das Backend authentisiert sich dabei bei Rasa X ~\ref{subsec:rasa-x} und holt sich alle Konversationen.
SchlieÃŸlich bereitet es die Konversationen auf und sendet sie an das Dashboard.

\section{Backend}\label{sec:backend}
\setauthor{Felix Dumfarth}

Das Quarkus ~\ref{quarkus} Backend hat die Aufgabe, mit Rasa X zu kommunizieren und die Konversationsdaten fÃ¼r das Dashboard aufzubereiten und zu senden.

Dieses Backend besitzt folgende Endpoints:

\begin{itemize}
    \item GET /api/conversations
    \item GET /api/conversations/{id}
    \item POST /api/feedback
    \item GET /api/feedback
    \item GET /api/file/{filename}
    \item PUT /api/file/{filename}
\end{itemize}

Bei den beiden \texttt{conversations} Endpoints muss man sich zunÃ¤chst authentisieren und sich einen Bearer Token von Rasa x holen, damit auf die anderen Rasa X Endpoints zugegriffen werden kann.

\subsection{GET /api/conversations}
Der Endpoint ruft zuerst die getAuth() Funktion auf, um den Bearer Token zu erhalten.

Danach wird der Rasa X GET Endpoint ``/api/conversations'', mit dem Bearer Token im Header aufgerufen.
Von diesem Endpoint wird ein JSON Objekt zurÃ¼ckgegeben, das die Konversationen enthÃ¤lt, aber zusÃ¤tzlich noch viele andere irrelevante Daten, deshalb filtert sich das Backend wirklich nur ID des Senders, die Zeit und die Anzahl von Nachrichten der Unterhaltungen heraus und gibt diese zurÃ¼ck.

\subsection{GET /api/conversations/{id}}
Der Endpoint \texttt{/api/conversations/{id}} ruft zuerst die \texttt{getAuth()} Funktion auf, um den Bearer Token zu erhalten.

Um nur die Nachrichten einer gezielten Unterhaltung zu erhalten, wird der Rasa X Endpoint \texttt{/api/conversations/{id}/messages}, mit dem Bearer Token im Header aufgerufen.
Die Response wird auch in dieser Form schon zurÃ¼ckgeben.

\subsection{POST /api/feedback}
Der Endpoint \texttt{/api/feedback} erhÃ¤lt ein JSON Objekt mit den Daten des Feedback-Formulars und speichert diese in die Datenbank.

\subsection{GET /api/feedback}
Der Endpoint \texttt{/api/feedback} liest alle Feedbacks aus der Datenbank aus und gibt diese zurÃ¼ck.

\subsection{GET /api/file/{filename}}
Der Endpoint \texttt{/api/file/{filename}} liest die im URL angegeben Datei aus dem Filesystem aus und gibt diese zurÃ¼ck.
Die mÃ¶glichen Dateinamen sind:

\begin{itemize}
    \item nlu.yml
    \item rules.yml
    \item stories.yml
    \item config.yml
    \item domain.yml
\end{itemize}

\subsection{PUT /api/file/{filename}}
Der Endpoint \texttt{/api/file/{filename}} erhÃ¤lt den Inhalt aus dem File, welches auch im URL angegeben wurde und dieses dann im Filesystem Ã¼berschreibt.

\section{Chat Widget}\label{sec:chat-widget}
Der Chatbot der HTL Leonding sollte auf der Schulhomepage als Chatblase angezeigt werden und verschiedene Elemente, wie Buttons und Links unterstÃ¼tzen.

\subsection{Konzept}
WÃ¤hrend den AnfÃ¤ngen der vorliegenden Arbeit wurde ein Konzept erstellt, um das Design des Chatbots festzulegen.
Lange Zeit wurde der Chatbot, wÃ¤hrend der Entwicklung, unter dem Namen "Leon" gefÃ¼hrt.
Dies wurde jedoch im spÃ¤teren Verlauf geÃ¤ndert und "Leon" wurde Teil des langjÃ¤hrigen "Leonie Projektes" der HTL Leonding.

\begin{figure}[hbt!]
    \centering
    \includegraphics[scale=0.2]{pics/conceptBotClosed}
    \caption{Konzept Chatbot geschlossen}
    \label{fig:impl:conceptBotClosed}
\end{figure}
\begin{figure}[hbt!]
    \centering
    \includegraphics[scale=0.2]{pics/conceptBotOpen}
    \caption{Konzept Chatbot geÃ¶ffnet}
    \label{fig:impl:conceptBotOpen}
\end{figure}

\subsection{Umsetzung}
Umgesetzt wurde das Frontend mithilfe von Angular.
Die Chatblase ist eine eigene Komponente, die durch CSS immer rechts unten fixiert ist.
Die Farben des Chatbots sollten dabei an die HTL Leonding erinnern, weshalb ein Farbverlauf aus Farben des HTL-Logos erstellt wurde.

Jedoch begann der Chatbot ganz anders und zu Beginn wurde der Bot als ganze Seite entwickelt und nicht nur als Chatblase.
Dies ist auf der Abbildung ~\ref{fig:impl:conceptBotFullPage} zu sehen.

\begin{figure}[hbt!]
    \centering
    \includegraphics[scale=0.2]{pics/fullPageBot}
    \caption{Chatbot auf einer ganzen Seite}
    \label{fig:impl:conceptBotFullPage}
\end{figure}

Dabei war dies nicht das endgÃ¼ltige Ziel und so kam es dazu, dass der Bot schnell zur Chatblase umgewandelt wurde.
Zum Testen war die HTL Leonding Seite mithilfe eines IFrames eingebunden und zusÃ¤tzlich die Chatblasen Komponente.

Um das GesprÃ¤ch in eine Richtung zu lenken, wurden Buttons eingefÃ¼hrt, die nach fast jeder Antwort mÃ¶gliche Folgefragen vorschlagen.
Solche VorschlÃ¤ge sind auf der Abbildung ~\ref{fig:impl:bot} zu sehen.

\begin{figure}[hbt!]
    \centering
    \includegraphics[scale=0.2]{pics/finalBot.png}
    \caption{Chatbot}
    \label{fig:impl:bot}
\end{figure}

Die Buttons werden von Rasa mit der Antwort auf die Frage mitgeschickt.
Wenn eine Benutzerin oder ein Benutzer auf einen der Buttons drÃ¼ckt, wird nicht der Text des Buttons an Rasa geschickt, sondern direkt die Bezeichnung des Intents mit einem ``/'' davor, da Rasa dies auch erkennt.

Um Bewertungen von echten Benutzern einzuholen, wurde auÃŸerdem eine Feedback-Seite eingefÃ¼hrt.
Auf dieser kann die Benutzerin oder der Benutzer eine Bewertung zwischen 1 und 5 Sternen abgeben und auch einen Text absenden.

\begin{figure}[hbt!]
    \centering
    \includegraphics[scale=0.3]{pics/feedback}
    \caption{Feedback Fenster}
    \label{fig:impl:feedback}
\end{figure}

Das Chatfenster wurde in wesentliche 3 Bereiche geteilt, die in Abbildung ~\ref{fig:impl:chatWidget} zu sehen sind.

\begin{figure}[hbt!]
    \centering
    \includegraphics[scale=0.4]{pics/chatWidgetStructure}
    \caption{Aufbau vom Chat Fenster}
    \label{fig:impl:chatWidget}
\end{figure}

\subsubsection{Avatar}
Wie bereits erwÃ¤hnt, existiert der virtuelle Avatar der Leonie in Form einer 3D Pyramide und einer Website mit einem 3D Modell.
Um Verwirrung zu vermeiden, wurde entschieden, dass der Chatbot auch in ``Leonie'' umbenannt werden soll.
Bei der ursprÃ¼nglichen Leonie handelt es sich um ein 3D Model (Abbildung ~\ref{fig:impl:leonie}).
Da dies aber nicht ganz zu einem Profilbild in einem Chat passen wÃ¼rde, wurde mit ``Adobe Illustrator'' eine 2D-Grafik erstellt.
Diese besteht aus einer fÃ¤rbigen Silhouette, welche die 3D-Leonie darstellt (Abbildung ~\ref{fig:impl:leonieTrans}).

\begin{figure}[hbt!]
    \centering
    \includegraphics[scale=0.5]{pics/AvatarLeonie}
    \caption{3D Leonie}
    \label{fig:impl:leonie}
\end{figure}

\begin{figure}[hbt!]
    \centering
    \includegraphics[scale=0.3]{pics/LeonieTrans}
    \caption{2D Leonie}
    \label{fig:impl:leonieTrans}
\end{figure}

\section{Dashboard}\label{sec:dashboard}
\setauthor{Felix Dumfarth}

Um alle GesprÃ¤che, sowie die Bewertungen der Benutzerinnen und Benutzer anzuzeigen, wurde ein Dashboard eingefÃ¼hrt, wo nur diese FunktionalitÃ¤ten gegeben sind.
Im Laufe der Arbeit wurde dieses dann erweitert, um fÃ¼r den Leobot Conversation Cycle ~\ref{subsec:leobot-conversation-cycle} als Seite zu dienen.

\subsection{Conversation-Driven Development}\label{cdd}
\setauthor{Felix Dumfarth}

Rasa empfiehlt fÃ¼r die Entwicklung von Chatbots ``Conversation-Driven Development'', kurz CDD.\cite{cdd}
CDD beschreibt dabei eine Entwicklungsstrategie, in der der Chatbot nach Konversationen mit echten Usern verbessert wird.

Bei CDD wird empfohlen, dass man seinen Chatbot mÃ¶glichst frÃ¼h Personen zur VerfÃ¼gung stehlt und so beobachten kann, welche Intents die echten Benutzerinnen und Benutzer erwarten und wie sie ihre Anfragen formulieren.
Als Entwicklerin oder Entwickler kann man diese nun bei Bedarf hinzufÃ¼gen.


\subsection{Leobot Conversation Cycle}\label{subsec:leobot-conversation-cycle}
\setauthor{Felix Dumfarth}

\begin{figure}[hbt!]
    \centering
    \includegraphics[scale=0.2]{pics/LeoCircle}
    \caption{Leobot Conversation Cycle}
    \label{fig:impl:ConversationCycle}
\end{figure}

CDD ~\ref{cdd} wird mithilfe des Leobot Conversation Cycle umgesetzt.
Der Leobot Conversation Cycle ist ein Workflow, welcher dazu dient, den Leobot zu Ã¼berprÃ¼fen und zu erweitern.
Der Workflow besteht dabei aus folgenden Schritten:

\begin{itemize}
    \item Unterhalten
    \item ÃœberprÃ¼fen
    \item Verbessern
    \item Trainieren
\end{itemize}

Diese 4 Schritte werden immer wieder durchgefÃ¼hrt, um den Chatbot dauerhaft zu verbessern.

\subsubsection{Unterhalten}
Das Unterhalten ist der erste Schritt des Leobot Conversation Cycles.
In diesem Schritt werden dem Bot Fragen Ã¼ber die HTL Leonding und deren Produktangebot gestellt, die er anschlieÃŸend beantworten soll.
Dies passiert wÃ¤hrend Unterhaltungen im Chat auf der Schulhomepage mit echten Personen.
Diese Unterhaltungen werden schlieÃŸlich alle gespeichert.

\subsubsection{ÃœberprÃ¼fen}

Das ÃœberprÃ¼fen stellt den zweiten Schritt des Leobot Conversation Cycles dar.
In diesem Schritt wird vom Schulpersonal oder Verantwortlichen Ã¼berprÃ¼ft, ob der Bot die Fragen richtig beantwortet und erkannt hat oder ob Verbesserungspotenzial besteht

\subsubsection{Verbessern}
Das Verbessern ist der dritte Schritt des Leobot Conversation Cycles.
In diesem Schritt wird der Bot verbessert, das bedeutet, dass versucht wird, dass die Fehler verbessert werden.
Je nachdem, wo der Fehler des Bots liegt, muss hier anders gearbeitet werden.
Wenn es sich um einen eigentlich bekannten Intent handelt, jedoch die Formulierung des Benutzers nicht erkannt wurde, wird die Eingabe des Users zu den Trainingsdaten hinzugefÃ¼gt.

Falls jemand aber eine Frage stellt, zu der es noch keinen passenden Intent gibt, so wird ein ganz neuer Intent zu den Trainingsdaten hinzugefÃ¼gt.

\subsubsection{Trainieren}
Das Trainieren ist der vierte Schritt des Leobot Conversation Cycles.
In diesem Schritt werden die Trainingsdaten an den Bot Ã¼bergeben und dieser wird trainiert.
Nachdem er fertig trainiert wurde, wechselt er auf das neu trainierte Model.

Und nun beginnt der Leobot Conversation Cycle wieder von vorne.

\subsubsection{Regelkreis}
\setauthor{Lukas Starka}

Dieser Vorgang erinnert dabei stark an einen Regelkreis.
Ein solcher Regelkreis ist in Abbildung ~\ref{fig:regelkreis} zu sehen und dieser fÃ¼hrt eine RegelgrÃ¶ÃŸe auf einen gewÃ¼nschten Sollwert.
Die Hauptkomponenten des Regelkreises sind der Regler und die Regelstrecke.
Beispielhaft ist die Regelstrecke ein Auto und die Fahrerin oder der Fahrer der Regler.
Dabei nimmt die Lenkerin oder der Lenker gewisse Parameter zur Hilfe, durch die entschieden wird, ob das Auto gelenkt, gebremst oder beschleunigt werden soll.
Diese Signale sind beispielsweise die aktuelle Geschwindigkeit, die Position des Autos oder die FahrbahnverhÃ¤ltnisse.
Beim Regelkreis wird also eine RegelgrÃ¶ÃŸe Ã¼ber ein Eingangssignal der Regelstrecke zurÃ¼ckgefÃ¼hrt und auf einen gewÃ¼nschten Wert gebracht.
Der Regelkreis wird oft bei der Regelung von Heizungen eingesetzt ~\ref{fig:heizungRegelKreis}.\cite{regelkreis, regelkreisBeispiel}

\begin{figure}[hbt!]
    \centering
    \includegraphics[scale=0.8]{pics/regelkreis}
    \caption{Allgemeiner Regelkreis ~\cite{regelkreis}}
    \label{fig:regelkreis}
\end{figure}

\begin{figure}[hbt!]
    \centering
    \includegraphics[scale=0.8]{pics/regelkreis_heizung}
    \caption{Regelkreis am Beispiel einer Heizung ~\cite{regelkreis}}
    \label{fig:heizungRegelKreis}
\end{figure}

Ein Regelkreis wird dabei entweder durch eine Ã„nderung der SollgrÃ¶ÃŸe oder durch Auftreten einer StÃ¶rung ausgelÃ¶st.
Beim Leobot Conversation Cycle wird der Regelkreis demzufolge ausgelÃ¶st, wenn eine Interaktion mit einem User stattfand, bei der der Bot eine falsche Antwort gegeben hat.
Die Messeinrichtung ist dabei das Dashboard ~\ref{sec:dashboard}, das alle Unterhaltungen auflistet und diese grafisch veranschaulicht.
Durch den eingebauten Editor ist die MÃ¶glichkeit gegeben, dass direkt die Files bearbeitet werden, sodass der Bot in Zukunft auch auf diese Fragestellung die richtige Antwort parat hat.
Der Sollwert wird also in den Regler eingegeben und anschlieÃŸend wird das Modell basierend auf den neuen Dateien neu trainiert.
Dies stellt dabei die Stelleinrichtung des Regelkreises dar und der Kreislauf kann von vorne beginnen, sollte erneut eine StÃ¶rgrÃ¶ÃŸe auftreten oder die SollgrÃ¶ÃŸe verÃ¤ndert werden.


\subsection{Warum das Dashboard}
\setauthor{Felix Dumfarth}
Die OberflÃ¤che von Rasa X bietet MÃ¶glichkeiten Sachen zu verÃ¤ndern, die man als normale Verwaltungsperson nicht unbedingt benÃ¶tigt, wie zum Beispiel Zugriff auf die Pipeline, Git und die ganzen trainierten Modelle.
Das sind alles Funktionen, die man als Verwaltungsperson nicht benÃ¶tigt, man sollte wirklich nur das sehen, was man auch verÃ¤ndern muss.

\subsection{Umsetzung}
\setauthor{Felix Dumfarth}

\subsubsection{Authentifizierung}
Da nicht jeder auf das ``Gehirn'' des Bots zugreifen soll, ist das Dashboard Benutzer- und PasswortgeschÃ¼tzt.
AuÃŸerdem soll in der Zukunft die MÃ¶glichkeit offen sein, dass manche Userrollen nur auf gewisse Inhalte Zugriff haben.

Die Authentifizierung wird Ã¼ber das Backend mit property file based authentication ~\cite{authentication} durchgefÃ¼hrt.

\begin{figure}[hbt!]
    \centering
    \includegraphics[scale=0.2]{pics/signin}
    \caption{Anmeldefenster}
    \label{fig:impl:signin}
\end{figure}

Man kann sich alle vergangenen Unterhaltungen ansehen, sowie die nlu.yml, stories.yml, rules.yml, domain.yml Dateien direkt im Monaco Editor bearbeiten und speichern.

\begin{figure}[hbt!]
    \centering
    \includegraphics[scale=0.2]{pics/dashboardConvo}
    \caption{Dashboard}
    \label{fig:impl:dashConv}
\end{figure}

Die Unterhaltungen kann man zur Ãœbersicht auch nach Datum filtern, wie in Abbildung ~\ref{fig:impl:dashboardDate} zu sehen ist.

\begin{figure}[hbt!]
    \centering
    \includegraphics[scale=0.2]{pics/dashboardDate}
    \caption{Dashboard nach Datum gefiltert}
    \label{fig:impl:dashboardDate}
\end{figure}

Im Editor wurden auch Code-VorschlÃ¤ge benutzt um das Einarbeiten von neuen Inhalten fÃ¼r die Benutzerinnen und Benutzer zu vereinfachen.

\begin{figure}[hbt!]
    \centering
    \includegraphics[scale=0.2]{pics/dashboardCodeSuggestion}
    \caption{VorschlÃ¤ge}
    \label{fig:impl:dashboardCodeSuggestion}
\end{figure}
\begin{figure}[hbt!]
    \centering
    \includegraphics[scale=0.2]{pics/dashboardSuggestionMade}
    \caption{Vorschlag benutzt}
    \label{fig:impl:dashboardCodeSuggestionMade}
\end{figure}

Dabei wurde sich fÃ¼r einen Editor entschieden, weil die Implementierung eines eigenen Formulars zu aufwendig im Zusammenhang fÃ¼r die Diplomarbeit gewesen wÃ¤re.

\section{Einbindung in Wordpress}
Die HTL Leonding Website ist eine Wordpress Seite, deshalb musste der Chatbot als Webkomponente mit Angular Elements ~\ref{subsec:angular-elements} exportiert werden, dass er dort eingebunden werden kann.

Auf WordPress wurde das Plugin ``Shortcoder'' ~\cite{shortcoder} installiert, dieses ermÃ¶glicht es Code Teile zu speichern.
Im Shortcoder MenÃ¼ wurde ein neuer Shortcode mit der von uns implementierten Webkomponente erstellt.

\begin{figure}[hbt!]
    \centering
    \includegraphics[scale=0.2]{pics/shortcoder}
    \caption{Shortcoder in WordPress Plugin Manager}
    \label{fig:impl:shortcoder}
\end{figure}

Auf der WordPress Seite wird nun der Shortcode eingefÃ¼gt und somit der Chatbot eingebunden.

\begin{figure}[hbt!]
    \centering
    \includegraphics[scale=0.2]{pics/wordpressedit}
    \caption{WordPress Editor}
    \label{fig:impl:wordpressedit}
\end{figure}

\begin{figure}[hbt!]
    \centering
    \includegraphics[scale=0.2]{pics/wordpresspage}
    \caption{WordPress Seite mit Chatbot}
    \label{fig:impl:wordpresspage}
\end{figure}

\section{Deployment}

\subsection{GitHub Actions}

Die praktische Arbeit besteht aus sehr vielen einzelnen Projekten, wie dem Chat, Dashboard und Rasa selbst, diese haben alle verschiedenen Funktionen, bei vielen der GitHub Projekte wurde mithilfe von GitHub Actions ~\ref{subsec:github-actions} das Deployment automatisiert.

\subsubsection{Action Server}
Der Rasa Custom Action Server wird mithilfe von GitHub Actions auf das LeoCloud Docker Registry geladen.

\begin{lstlisting}[language=yaml,label={lst:actionserveryml},caption={action\_server.yml}]{actionserver.yml}]
on:
  push:
    branches:
      - main
    paths:
    - 'rasa-docker-prototype/actions/**'

jobs:
  build_and_deploy:
    runs-on: ubuntu-latest
    name: Build Action Server image and upgrade Rasa X deployment
    steps:
    - name: Checkout repository
      uses: actions/checkout@v2

    - id: action_server
      name: Build an action server with a custom actions
      uses: RasaHQ/action-server-gha@main
      # Full list of parameters: https://github.com/RasaHQ/action-server-gha/tree/master#input-arguments
      with:
        actions_directory: 'rasa-docker-prototype/actions/'
        docker_registry: registry.cloud.htl-leonding.ac.at
        requirements_file: rasa-docker-prototype/actions/requirements.txt
        docker_image_name: 'f.dumfarth/leobot'
        docker_registry_login: ${{ secrets.LEO_LOGIN }}
        docker_registry_password: ${{ secrets.LEO_PASS }}
        # More details about github context:
        # https://docs.github.com/en/actions/reference/context-and-expression-syntax-for-github-actions#github-context
        #
        # github.sha - The commit SHA that triggered the workflow run
        docker_image_tag: 'leonie'
        docker_registry_push: true
\end{lstlisting}

Um den Action Server zu bauen, wird die ``RasaHQ/action-server-gha@main'' Action ~\cite{actionServerAction} benutzt.

Die genutzten Argumente dabei sind:

%\begin{center}
%    \begin{tabular}{ |c|c| }
%        \hline
%        actions\_directory & Der Ordner in dem sich die Actions befinden \\
%        docker\_registry & Das Docker Registry wohin der Action Server hochgeladen werden soll \\
%        requirements\_file & Der Pfad zur requirements.txt Datei \\
%        docker\_image\_name & Der Name des Docker Images \\
%        docker\_registry\_login & Dein Username fÃ¼r das Docker Registry, am besten in einem Secret \\
%        docker\_registry\_password & Dein Passwort fÃ¼r das Docker Registry, am besten in einem Secret \\
%        docker\_image\_tag & der Tag des Docker Images \\
%        docker\_registry\_push & True oder False ob das Docker Image auf das Docker Registry hochgeladen werden soll \\
%        \hline
%    \end{tabular}
%\end{center}

\begin{itemize}
    \item actions\_directory: Der Ordner in dem sich die Actions befinden.
    \item docker\_registry: Das Docker Registry wohin der Action Server hochgeladen werden soll.
    \item requirements\_file: Der Pfad zur requirements.txt Datei.
    \item docker\_image\_name: Der Name des Docker Images.
    \item docker\_registry\_login: Dein Username fÃ¼r das Docker Registry, am besten in einem Secret.
    \item docker\_registry\_password: Dein Passwort fÃ¼r das Docker Registry, am besten in einem Secret.
    \item docker\_image\_tag: der Tag des Docker Images.
    \item docker\_registry\_push: True oder False ob das Docker Image auf das Docker Registry hochgeladen werden soll.
\end{itemize}

Auf der virtuellen Maschine in der \texttt{docker-compose.yml} Datei muss noch das Image angeben werden.
Dies wird in Listing ~\ref{lst:dockercomposeyml} beschrieben ist.

\begin{lstlisting}[language=yaml,label={lst:dockercomposeyml},caption={docker-compose.yml}]{docker-compose.yml}]
app:
restart: always
image: "registry.cloud.htl-leonding.ac.at/f.dumfarth/leobot:leon"
expose:
- "5055"
depends_on:
- rasa-production
\end{lstlisting}

Dabei bekommt das Image den Namen ``leobot'' und den Tag ``leon''.

\subsubsection{Backend}
Das Backend wird mithilfe von GitHub Actions automatisiert gebaut, der Workflow baut das .jar file und dieses wird dann Ã¼ber SSH auf die virtuelle Maschine geladen.

\begin{lstlisting}[language=yaml,label={lst:ciyml},caption={ci.yml}]{ci.yml}]
name: Quarkus Codestart CI

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - name: Set up JDK 17
        uses: actions/setup-java@v2
        with:
          distribution: 'temurin'
          java-version: '17'
      - name: Build
        run: ./mvnw clean package -Dquarkus.package.type=uber-jar -B
      - name: install ssh key
        uses: webfactory/ssh-agent@v0.5.3
        with:
          ssh-private-key: ${{ secrets.SSH_SERVER_PRIVATE_KEY }}
      - name: create .ssh/known_hosts
        run: |
          ssh-keyscan -H -t rsa -v ${{ secrets.SERVER }}  >> ~/.ssh/known_hosts
      - name: copy binaries to vm
        run: |
          echo "Hallo ich bin hier"
          ls -l target/
          scp target/leon-1.0.0-SNAPSHOT-runner.jar ${{ secrets.SERVER_USER }}@${{ secrets.SERVER }}:
\end{lstlisting}

\subsubsection{Frontend}
Die Chat-Seite ~\ref{sec:chat-widget} sowie das Dashboard ~\ref{sec:dashboard} werden mithilfe von GitHub Actions automatisiert gebaut und auf GH Pages verÃ¶ffentlicht.
Dies passiert mit dem Workflow in der \texttt{build-and-deploy.yml} Datei:

\begin{lstlisting}[language=yaml,label={lst:buildanddeployyml},caption={build-and-deploy.yml}]{build-and-deploy.yml}]
name: deploy to gh-pages

on:
  push:
    branches:
      - 'main'

jobs:
  build:
    name: Build âš™
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v2
      - name: Use Node 12.x
        uses: actions/setup-node@v1
        with:
          node-version: '12.x'
      - name: Install dependencies
        run: npm i
      - name: Build
        run: npm run build
      - name: Archive build
        if: success()
        uses: actions/upload-artifact@v1
        with:
          name: dist
          path: dist
  deploy:
    name: Deploy ðŸš€
    runs-on: ubuntu-latest
    needs: build
    steps:
      - name: Checkout
        uses: actions/checkout@v1
      - name: Download build
        uses: actions/download-artifact@v1
        with:
          name: dist
      - name: Deploy to GitHub Pages
        uses: JamesIves/github-pages-deploy-action@releases/v3
        with:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          BRANCH: gh-pages
          FOLDER: dist/LeoBotHtlLeonding
\end{lstlisting}

Diese Action hat zwei Jobs, die ``build'' und ``deploy'' genannt werden.

Die verschiedenen Tasks in Build laden zuerst eine Node Version herunter, installieren die Dependencies, builden das Angular Projekt und schlieÃŸlich wird dist in die Github Actions Artifacts gespeichert.

Beim Deploy Task wird dist von den Artefakten heruntergeladen und wird in den Zweig ``gh-pages'' des Repositories gespeichert.

\subsubsection{Rasa}
\setauthor{Felix Dumfarth}

Wenn in das GH Repo etwas gepushed wird, wird mithilfe einer GitHub Action Rasa trainiert und das Model auf die VM geladen.

\begin{lstlisting}[language=yaml,label={lst:rasadeployyml},caption={rasa\_deploy.yml}]{rasa\_deploy.yml}]
name: Deploy Rasa to vm

on:
  push:
    branches:
      - 'main'
    paths:
      - 'rasa-docker-prototype/**'
  pull_request:
    branches:
      - 'main'

  workflow_dispatch:

jobs:
  branch:
    name: Deploy ðŸš€
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v1
      - name: Deploy to Branch
        uses: JamesIves/github-pages-deploy-action@releases/v3
        with:
          GITHUB_TOKEN: ${{ secrets.TOKEN }}
          BRANCH: rasa-chatbot
          FOLDER: rasa-docker-prototype
  tests:
    name: Train and Test Rasa
    runs-on: ubuntu-latest
    needs: branch
    steps:
      - uses: actions/checkout@v2
        with:
          ref: rasa-chatbot
      - name: Train and Test Rasa
        uses: RasaHQ/rasa-train-test-gha@main
        with:
          test_type: all
          rasa_version: 2.8.12-full
          data_validate: true
          test_args: --fail-on-prediction-errors
          rasa_train: true
          rasa_test: true
      - name: Upload model
        uses: actions/upload-artifact@master
        with:
          name: model
          path: models
  deploy:
    name: "Deploy to vm"
    runs-on: ubuntu-latest
    needs: tests
    steps:
      - name: Download model
        uses: actions/download-artifact@v2
        with:
          name: model
          path: models
      - name: Copy model to vm
        uses: garygrossgarten/github-action-scp@release
        with:
          local: models
          remote: /home/chatadm/leobot/models
          host: ${{ secrets.SSH_HOST }}
          username: ${{ secrets.SSH_USER }}
          privateKey: ${{ secrets.SSH_KEY }}
      - name: Configure SSH
        run: |
          mkdir -p ~/.ssh/
          echo "$SSH_KEY" > ~/.ssh/staging.key
          chmod 600 ~/.ssh/staging.key
          cat >>~/.ssh/config <<END
          Host staging
            HostName $SSH_HOST
            User $SSH_USER
            IdentityFile ~/.ssh/staging.key
            StrictHostKeyChecking no
          END
        env:
          SSH_USER: ${{ secrets.SSH_USER }}
          SSH_KEY: ${{ secrets.SSH_KEY }}
          SSH_HOST: ${{ secrets.SSH_HOST }}
      - name: Copy model to Rasa X
        run: ssh staging 'cd /home/chatadm/leobot/models && ./upload-latest-model.sh'
\end{lstlisting}

Es wird zuerst geschaut, ob der Push wirklich auf den Branch ``main'' geschickt wurde und dort im Ordner ``rasa-docker-prototype'' sich etwas verÃ¤ndert hat.
Wenn dies zutrifft, wird der Workflow ausgefÃ¼hrt.
Im Job \texttt{branch} wird zuerst der Ordner, der mithilfe des ``FOLDER:'' Arguments angegeben wurde, also ``rasa-docker-prototype'' auf den BRANCH, der mit ``BRANCH:'' angegeben wurde, also ``rasa-chatbot'' geladen.
Im Job \texttt{tests} wird zuerst definiert, dass der Job ``branch'' benÃ¶tigt wird bevor ``tests'' ausgefÃ¼hrt werden kann.
Dies wird mit dem ``needs:'' Argument definiert.
Nun wird die ``rasa-train-test-gha@main'' Action geladen.
Diese Action trainiert das Modell und testet dieses dann direkt.
Nachdem das Model trainiert und getestet wurde, wird das Model mit dem Job ``upload-artifact'' in die Artefakte hochgeladen.

Nun wird im \texttt{deploy} Job zuerst das Modell heruntergeladen.
Danach wird mit der Action ``garygrossgarten/github-action-scp@release'' das Modell Ã¼ber SSH auf die virtuelle Maschine geladen.
Mit dem ``remote'' Argument wird der Pfad auf die VM angegeben, hierbei ist dieser ``/home/chatadm/leobot/models''.
AuÃŸerdem werden Secret Variablen ``SSH\_HOST'', ``SSH\_USER'' und ``SSH\_KEY'' definiert, diese werden mit ``secrets.SSH\_HOST'', ``secrets.SSH\_USER'' und ``secrets.SSH\_KEY'' angegeben.
Danach wird der Host ``staging'' mit dem User ``chatadm'' und der Private Key ``staging.key''angelegt
Mit diesem Host wird dann in dem Task ``Copy model to Rasa X'' wird in den /home/chatadm/leobot/models Ordner gewechselt, wo zuvor das Model hochgeladen wurde.
Dann wird das Shell-Skript ``upload-latest-model.sh'' ausgefÃ¼hrt.
Dieses Shell-Skript beinhaltet eine verÃ¤nderte Version des Befehls, der das Modell auf Rasa X Ã¼ber die API \footnote{API Token zur Sicherheit im Kapitel entfernt} lÃ¤dt.

Der Befehl zum Hochladen des Modells auf Rasa X, kann in der Rasa X OberflÃ¤che, wie in Abbildung ~\ref{fig:impl:rasaxapimodel} aufgezeigt, gefunden werden.

\begin{figure}[hbt!]
    \centering
    \includegraphics[scale=0.2]{pics/rasaxapimodel}
    \caption{Rasa X OberflÃ¤che mit dem Befehl zum Model upload}
    \label{fig:impl:rasaxapimodel}
\end{figure}

\begin{lstlisting}[language=bash,label={lst:uploadlatestmodelshdefault},caption={Befehl zum Model Upload von Rasa X }]{Rasa X API Model Upload}
curl -k -F "model=@my_model.tar.gz" "http://leobot.htl-leonding.ac.at:4200/api/projects/default/models?api_token=TOKEN"
\end{lstlisting}

Dieser Befehl wurde angepasst, sodass er immer das neuste Model hochlÃ¤dt, wie in Listing ~\ref{lst:uploadlatestmodelsh} zu sehen ist.

\begin{lstlisting}[language=bash,label={lst:uploadlatestmodelsh},caption={upload-latest-model.sh}]{upload-latest-model.sh}]
curl -k -F "model=@$(ls -t *tar.gz | head -1)" "localhost:4200/api/projects/default/models?api_token=TOKEN"
\end{lstlisting}

